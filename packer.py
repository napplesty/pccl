#!/usr/bin/env python3
"""
ä»£ç æ‰“åŒ…è„šæœ¬ - å°†å¤šä¸ªç›®å½•çš„ä»£ç æ–‡ä»¶åˆå¹¶ä¸ºå•ä¸ªæ–‡æœ¬æ–‡ä»¶
ç›´æ¥æŒ‡å®šæ–‡ä»¶å¤¹åœ°å€ï¼Œæ— éœ€å‘½ä»¤è¡Œå‚æ•°
"""

import os
import datetime
from pathlib import Path

def pack_code_directories():
    """ç›´æ¥æ‰“åŒ…æŒ‡å®šç›®å½•çš„ä»£ç æ–‡ä»¶"""
    
    # ========== åœ¨è¿™é‡Œä¿®æ”¹é…ç½® ==========
    
    # è¦æ‰“åŒ…çš„ç›®å½•åˆ—è¡¨ï¼ˆç›´æ¥åœ¨è¿™é‡Œä¿®æ”¹ï¼‰
    directories_to_pack = [
        'csrc',
        'include'
        # å¯ä»¥æ·»åŠ æ›´å¤šç›®å½•ï¼Œä¾‹å¦‚ï¼š
        # 'src',
        # 'lib',
        # 'utils'
    ]
    
    # è¾“å‡ºæ–‡ä»¶å
    output_filename = "code_context.txt"
    
    # è¦åŒ…å«çš„æ–‡ä»¶æ‰©å±•å
    target_extensions = {
        '.cc', '.cpp', '.c', '.h', '.hpp', '.cu', '.cuh',  # C/C++/CUDA
        '.py',  # Python
        '.java', '.js', '.ts', '.go', '.rs', '.php', '.rb',  # å…¶ä»–è¯­è¨€
        '.md', '.txt'  # æ–‡æ¡£
    }
    
    # è¦å¿½ç•¥çš„ç›®å½•å’Œæ–‡ä»¶æ¨¡å¼
    ignore_patterns = [
        '__pycache__', '*.pyc', 'node_modules', '.git', 
        '.svn', '.DS_Store', '*.so', '*.dll', '*.exe',
        '*.o', '*.a', '*.class', '*.jar', '*.war',
        '*.log', '*.tmp', '*.temp', 'build/', 'dist/',
        '*.egg-info', '.env', 'venv/', 'env/', '.venv'
    ]
    
    # ========== é…ç½®ç»“æŸ ==========
    
    print("å¼€å§‹ä»£ç æ‰“åŒ…...")
    print(f"æ‰“åŒ…ç›®å½•: {directories_to_pack}")
    print(f"è¾“å‡ºæ–‡ä»¶: {output_filename}")
    print(f"ç›®æ ‡æ‰©å±•å: {', '.join(sorted(target_extensions))}")
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    valid_dirs = []
    for directory in directories_to_pack:
        if os.path.exists(directory):
            valid_dirs.append(Path(directory).resolve())
            print(f"âœ“ æ‰¾åˆ°ç›®å½•: {directory}")
        else:
            print(f"âœ— ç›®å½•ä¸å­˜åœ¨: {directory}")
    
    if not valid_dirs:
        print("é”™è¯¯ï¼šæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆç›®å½•ï¼")
        return False
    
    total_files = 0
    total_size = 0
    file_stats = {}
    
    try:
        with open(output_filename, 'w', encoding='utf-8') as outfile:
            # å†™å…¥æ–‡ä»¶å¤´ä¿¡æ¯
            outfile.write(f"{'#'*80}\n")
            outfile.write("# ä»£ç ä¸Šä¸‹æ–‡æ‰“åŒ…æ–‡ä»¶\n")
            outfile.write(f"# ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            outfile.write(f"# æ‰“åŒ…ç›®å½•: {[str(d) for d in valid_dirs]}\n")
            outfile.write(f"# æ–‡ä»¶ç±»å‹: {', '.join(sorted(target_extensions))}\n")
            outfile.write(f"{'#'*80}\n\n")
            
            for directory in valid_dirs:
                outfile.write(f"\n{'#'*60}\n")
                outfile.write(f"# ç›®å½•: {directory}\n")
                outfile.write(f"{'#'*60}\n\n")
                
                # é€’å½’éå†ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
                for filepath in directory.rglob('*'):
                    if filepath.is_file():
                        # æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥è¯¥æ–‡ä»¶
                        if should_ignore_file(filepath, ignore_patterns):
                            continue
                        
                        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                        if filepath.suffix.lower() in target_extensions:
                            process_single_file(filepath, directory, outfile)
                            total_files += 1
                            
                            # è·å–æ–‡ä»¶å¤§å°ç”¨äºç»Ÿè®¡
                            try:
                                file_size = filepath.stat().st_size
                                total_size += file_size
                                ext = filepath.suffix.lower()
                                file_stats[ext] = file_stats.get(ext, 0) + 1
                            except:
                                pass
            
            # å†™å…¥ç»Ÿè®¡ä¿¡æ¯
            outfile.write(f"\n{'#'*80}\n")
            outfile.write("# æ‰“åŒ…ç»Ÿè®¡ä¿¡æ¯\n")
            outfile.write(f"# æ€»æ–‡ä»¶æ•°: {total_files}\n")
            outfile.write(f"# æ€»å¤§å°: {total_size} å­—èŠ‚\n")
            outfile.write("# æ–‡ä»¶ç±»å‹åˆ†å¸ƒ:\n")
            for ext, count in sorted(file_stats.items()):
                outfile.write(f"#   {ext}: {count} ä¸ªæ–‡ä»¶\n")
            outfile.write(f"{'#'*80}\n")
        
        print(f"\nâœ… æ‰“åŒ…å®Œæˆï¼")
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ–‡ä»¶æ•°é‡: {total_files}")
        print(f"   æ€»å¤§å°: {total_size} å­—èŠ‚")
        print(f"   è¾“å‡ºæ–‡ä»¶: {output_filename}")
        
        if file_stats:
            print(f"   æ–‡ä»¶ç±»å‹åˆ†å¸ƒ:")
            for ext, count in sorted(file_stats.items()):
                print(f"     {ext}: {count} ä¸ªæ–‡ä»¶")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ‰“åŒ…è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        return False

def should_ignore_file(filepath, ignore_patterns):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åº”è¯¥è¢«å¿½ç•¥"""
    import fnmatch
    
    for pattern in ignore_patterns:
        if fnmatch.fnmatch(filepath.name, pattern):
            return True
        if pattern.endswith('/') and pattern[:-1] in str(filepath):
            return True
    return False

def process_single_file(filepath, base_directory, outfile):
    """å¤„ç†å•ä¸ªæ–‡ä»¶ï¼šè¯»å–å†…å®¹å¹¶å†™å…¥è¾“å‡ºæ–‡ä»¶"""
    try:
        # è·å–ç›¸å¯¹è·¯å¾„
        relative_path = filepath.relative_to(base_directory)
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        try:
            stat = filepath.stat()
            file_size = stat.st_size
            modified_time = datetime.datetime.fromtimestamp(stat.st_mtime)
        except:
            file_size = 0
            modified_time = None
        
        # å†™å…¥æ–‡ä»¶å¤´
        outfile.write(f"\n{'='*80}\n")
        outfile.write(f"æ–‡ä»¶: {relative_path}\n")
        outfile.write(f"æ‰©å±•å: {filepath.suffix}\n")
        outfile.write(f"å¤§å°: {file_size} å­—èŠ‚\n")
        if modified_time:
            outfile.write(f"ä¿®æ”¹æ—¶é—´: {modified_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        outfile.write(f"{'='*80}\n\n")
        
        # è¯»å–å¹¶å†™å…¥æ–‡ä»¶å†…å®¹
        content = read_file_with_encoding(filepath)
        outfile.write(content)
        outfile.write('\n')  # æ–‡ä»¶é—´ç©ºè¡Œ
        
        print(f"âœ“ å·²å¤„ç†: {relative_path}")
        
    except Exception as e:
        print(f"âš ï¸  å¤„ç†æ–‡ä»¶å¤±è´¥ {filepath}: {e}")
        outfile.write(f"<å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}>\n")

def read_file_with_encoding(filepath):
    """å°è¯•ç”¨ä¸åŒç¼–ç è¯»å–æ–‡ä»¶"""
    encodings = ['utf-8', 'latin-1', 'cp1252', 'gbk', 'gb2312', 'iso-8859-1']
    
    for encoding in encodings:
        try:
            with open(filepath, 'r', encoding=encoding) as f:
                return f.read()
        except UnicodeDecodeError:
            continue
        except Exception:
            continue
    
    # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œå°è¯•äºŒè¿›åˆ¶è¯»å–
    try:
        with open(filepath, 'rb') as f:
            content = f.read()
        return f"<äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œå¤§å°: {len(content)} å­—èŠ‚>"
    except Exception as e:
        return f"<è¯»å–æ–‡ä»¶é”™è¯¯: {str(e)}>"

# é«˜çº§ç‰ˆæœ¬ï¼šæ”¯æŒæ›´å¤šå®šåˆ¶é€‰é¡¹
def advanced_pack_code(directories, output_file="code_context.txt", 
                      extensions=None, max_file_size=1024*1024):
    """é«˜çº§æ‰“åŒ…å‡½æ•°ï¼Œæ”¯æŒæ›´å¤šé€‰é¡¹"""
    if extensions is None:
        extensions = {'.cc', '.cpp', '.c', '.h', '.hpp', '.cu', '.py'}
    
    print(f"é«˜çº§æ‰“åŒ…æ¨¡å¼å¯åŠ¨...")
    print(f"ç›®å½•: {directories}")
    print(f"è¾“å‡º: {output_file}")
    print(f"æ‰©å±•å: {extensions}")
    print(f"æœ€å¤§æ–‡ä»¶å¤§å°: {max_file_size} å­—èŠ‚")
    
    file_count = 0
    skipped_files = []
    
    with open(output_file, 'w', encoding='utf-8') as outfile:
        outfile.write(f"ä»£ç æ‰“åŒ…æ–‡ä»¶ - ç”Ÿæˆæ—¶é—´: {datetime.datetime.now()}\n\n")
        
        for directory in directories:
            if not os.path.exists(directory):
                print(f"è·³è¿‡ä¸å­˜åœ¨çš„ç›®å½•: {directory}")
                continue
                
            for root, dirs, files in os.walk(directory):
                # è¿‡æ»¤å¿½ç•¥çš„ç›®å½•
                dirs[:] = [d for d in dirs if d not in ['.git', '__pycache__', 'node_modules']]
                
                for file in files:
                    filepath = os.path.join(root, file)
                    file_ext = os.path.splitext(file)[1].lower()
                    
                    if file_ext in extensions:
                        try:
                            # æ£€æŸ¥æ–‡ä»¶å¤§å°
                            file_size = os.path.getsize(filepath)
                            if file_size > max_file_size:
                                skipped_files.append(f"{filepath} (å¤§å°: {file_size} å­—èŠ‚)")
                                continue
                            
                            # å†™å…¥æ–‡ä»¶å†…å®¹
                            relative_path = os.path.relpath(filepath, directory)
                            outfile.write(f"\n{'='*60}\n")
                            outfile.write(f"æ–‡ä»¶: {relative_path}\n")
                            outfile.write(f"{'='*60}\n\n")
                            
                            content = read_file_with_encoding(Path(filepath))
                            outfile.write(content)
                            outfile.write('\n\n')
                            
                            file_count += 1
                            print(f"å·²æ·»åŠ : {relative_path}")
                            
                        except Exception as e:
                            print(f"é”™è¯¯å¤„ç†æ–‡ä»¶ {filepath}: {e}")
    
    print(f"\næ‰“åŒ…å®Œæˆï¼å…±å¤„ç† {file_count} ä¸ªæ–‡ä»¶")
    if skipped_files:
        print(f"è·³è¿‡äº† {len(skipped_files)} ä¸ªè¿‡å¤§æ–‡ä»¶:")
        for f in skipped_files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  {f}")
        if len(skipped_files) > 5:
            print(f"  ... è¿˜æœ‰ {len(skipped_files)-5} ä¸ªæ–‡ä»¶è¢«è·³è¿‡")
    
    return file_count

if __name__ == "__main__":
    # ä½¿ç”¨æ–¹æ³•1ï¼šç›´æ¥è°ƒç”¨ä¸»å‡½æ•°ï¼ˆæ¨èï¼‰
    pack_code_directories()
    
    # ä½¿ç”¨æ–¹æ³•2ï¼šé«˜çº§å®šåˆ¶ç‰ˆæœ¬
    # custom_dirs = ['csrc', 'include', 'src']
    # custom_exts = {'.cc', '.h', '.hpp', '.cu', '.py'}
    # advanced_pack_code(custom_dirs, "custom_context.txt", custom_exts)
